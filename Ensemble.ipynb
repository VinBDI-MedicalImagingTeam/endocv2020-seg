{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "from sklearn.metrics import f1_score\n",
    "import tifffile as tiff\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from cvcore.modeling.loss import binary_dice_metric, binary_iou_metric\n",
    "from cvcore.data.endocv_dataset import EDDDataset\n",
    "from cvcore.configs import get_cfg_defaults\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab external data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = []\n",
    "labels = []\n",
    "\n",
    "for img in os.listdir('data/Abnormal/'):\n",
    "    img_ids.append(os.path.join('Abnormal', img))\n",
    "    labels.append([0, 1, 0, 0, 0])\n",
    "\n",
    "for img in os.listdir('data/ETIS-LaribPolypDB/'):\n",
    "    img_ids.append(os.path.join('ETIS-LaribPolypDB/', img))\n",
    "    labels.append([0, 0, 0, 0, 1])\n",
    "\n",
    "for img in os.listdir('data/Kvasir-SEG/images/'):\n",
    "    img_ids.append(os.path.join('Kvasir-SEG/images/', img))\n",
    "    labels.append([0, 0, 0, 0, 1])\n",
    "    \n",
    "ext_df = pd.concat([pd.Series(img_ids), pd.DataFrame(labels)], 1)\n",
    "ext_df.columns = ['img', 'BE', 'suspicious', 'HGD', 'cancer', 'polyp']\n",
    "ext_df.to_csv('./data/external_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir = \"data/originalImages/\"\n",
    "masks_dir = \"data/masks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"BE\",\n",
    "    \"suspicious\",\n",
    "    \"HGD\",\n",
    "    \"cancer\",\n",
    "    \"polyp\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_labels = []\n",
    "img_ids = []\n",
    "\n",
    "for img in os.listdir(imgs_dir):\n",
    "    img_ids.append(img)\n",
    "    img_path = os.path.join(imgs_dir, img)\n",
    "    img_label = []\n",
    "    for cls in classes:\n",
    "        mask_path = os.path.join(masks_dir, img.replace(\".jpg\", f\"_{cls}.tif\"))\n",
    "        if os.path.exists(mask_path):\n",
    "            img_label.append(1)\n",
    "        else:\n",
    "            img_label.append(0)\n",
    "    img_labels.append(img_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.Series(img_ids), \n",
    "                pd.DataFrame(img_labels)], axis=1)\n",
    "df.columns = [\"img\"] + classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in classes:\n",
    "    print(f\"Class {cls} - num. samples {df[cls].value_counts()[0]}\")\n",
    "    \n",
    "NUM_FOLDS = 5\n",
    "SEED = 2709\n",
    "\n",
    "iterkfold = IterativeStratification(n_splits=5, random_state=SEED)\n",
    "\n",
    "x, y = df.iloc[:, 0].values, df.iloc[:, 1:].values\n",
    "for i, (train, test) in enumerate(iterkfold.split(x, y)):\n",
    "    print(x[train].shape, x[test].shape)\n",
    "    df.loc[train].to_csv(f\"data/train_fold{i}.csv\", index=False)\n",
    "    df.loc[test].to_csv(f\"data/valid_fold{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_threshold = [0.5] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_grid_thresholds = np.linspace(0.1, 0.6, 100)\n",
    "classes = [\n",
    "    \"BE\",\n",
    "    \"suspicious\",\n",
    "    \"HGD\",\n",
    "    \"cancer\",\n",
    "    \"polyp\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['b4_unet', 'b3_unet', 'resnet50_fpn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_threshold(inputs, targets,\n",
    "    grid_thresholds=np.linspace(0.1, 0.6, 100), \n",
    "    metric_func=f1_score):\n",
    "    num_classes = inputs.shape[1]\n",
    "    best_cls_thresholds = []\n",
    "    for i in range(num_classes):\n",
    "        class_inp = inputs[:, i]\n",
    "        class_tar = targets[:, i]\n",
    "        grid_scores = []\n",
    "        for thresh in _grid_thresholds:\n",
    "            grid_scores.append(metric_func(class_tar, class_inp > thresh))\n",
    "        best_t = grid_thresholds[np.argmax(grid_scores)]\n",
    "        best_score = np.max(grid_scores)\n",
    "        best_cls_thresholds.append(best_t)\n",
    "    return best_cls_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights: [1.0, 0.0, 0.0] Dice score: 0.8522069454193115 - IoU: 0.8279612064361572\n",
      "\n",
      "Weights: [0.0, 1.0, 0.0] Dice score: 0.8528971672058105 - IoU: 0.8286389708518982\n",
      "\n",
      "Weights: [0.0, 0.0, 1.0] Dice score: 0.8534929156303406 - IoU: 0.8297587633132935\n",
      "\n",
      "Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333] Dice score: 0.8470149040222168 - IoU: 0.8231855630874634\n"
     ]
    }
   ],
   "source": [
    "ens_mask_output_list = []\n",
    "valid_mask_list = []\n",
    "\n",
    "for seg_weights in [\n",
    "    [1., 0., 0.],\n",
    "    [0., 1., 0.],\n",
    "    [0., 0., 1.],\n",
    "#     [0.5, 0.4, 0.1],\n",
    "#     [0.6, 0.3, 0.1],\n",
    "#     [0.7, 0.2, 0.1],\n",
    "    [1./3, 1./3, 1./3]\n",
    "    \n",
    "]:\n",
    "    for i in range(5):\n",
    "        valid_mask = torch.load(f'thresholds_tuning/mask_{i}.pth')\n",
    "        ens_mask_output = 0\n",
    "        for model, w in zip(models, seg_weights):\n",
    "            if model == 'b4_unet':\n",
    "                model_output = torch.load(f'thresholds_tuning/{model}_fold{i}.pth')\n",
    "                model_output = F.interpolate(model_output, 384, \n",
    "                    mode='bilinear', align_corners=False)\n",
    "            else:\n",
    "                model_output = torch.load(f'thresholds_tuning/{model}_fold{i}.pth')\n",
    "            ens_mask_output += model_output * w\n",
    "        ens_mask_output_list.append(ens_mask_output)\n",
    "        valid_mask_list.append(valid_mask)\n",
    "    ens_mask_output = torch.cat(ens_mask_output_list, 0)\n",
    "    valid_mask = torch.cat(valid_mask_list, 0)\n",
    "    dice_score = binary_dice_metric(ens_mask_output, valid_mask, seg_threshold).mean().item()\n",
    "    iou = binary_iou_metric(ens_mask_output, valid_mask, seg_threshold).mean().item()\n",
    "    print(f'\\nWeights: {seg_weights} Dice score: {dice_score} - IoU: {iou}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_weights = [0.5, 0.4, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "\n",
    "ens_mask_pred = 0\n",
    "\n",
    "for m, seg_w in zip(models, seg_weights):\n",
    "    single_mask_pred = 0\n",
    "    for f in range(num_folds): # folds\n",
    "        if m == \"b4_unet\":\n",
    "            single_mask_pred += F.interpolate(\n",
    "                torch.load(f'./thresholds_tuning/{m}_fold{f}_test.pth'),\n",
    "                384, align_corners=False, mode='bilinear'\n",
    "                ) / num_folds\n",
    "        else:\n",
    "            single_mask_pred += torch.load(f'./thresholds_tuning/{m}_fold{f}_test.pth') / num_folds\n",
    "    ens_mask_pred += single_mask_pred * seg_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_mask_pred = torch.where(ens_mask_pred!=0, \n",
    "                            torch.sigmoid(ens_mask_pred), ens_mask_pred)\n",
    "ens_mask_pred = torch.stack([\n",
    "    ens_mask_pred[:, i, ...] > th\n",
    "    for i, th in enumerate(best_seg_thresholds)], 1)\n",
    "ens_mask_pred = ens_mask_pred.float()\n",
    "\n",
    "for out, i, o_sz in zip(ens_mask_pred, img_id, orig_size):\n",
    "    out = F.interpolate(out.unsqueeze(0), o_sz,\n",
    "        mode=\"bilinear\", align_corners=False)\n",
    "    out = out.squeeze(0)\n",
    "    out = out.cpu().numpy().astype(np.uint8) * 255\n",
    "    save_path = os.path.join(mask_pred_dir, i.replace(\".jpg\", \".tif\"))\n",
    "    tiff.imwrite(save_path, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANQUANGDAT ATOMIC BOMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seg_thresholds = [0.5] * 5\n",
    "\n",
    "# models = ['rx101-x448', 'rx50-x384-iter-focal']\n",
    "# seg_weights = [.7, .3]\n",
    "\n",
    "# models = ['rx101-x448', 'rx50-x384-iter-focal', 'rx101-fpn']\n",
    "# seg_weights = [.5, .3, .2]\n",
    "\n",
    "models = ['rx101-x448', 'rx50-x384-iter-focal', 'rx101-fpn', 'b4-fpn']\n",
    "seg_weights = [.45, .3, .2, .05]\n",
    "\n",
    "out_dir = 'dattran2346_kfold/'\n",
    "img_id = torch.load(f'{out_dir}test_img_ids.pth')\n",
    "orig_size = torch.load(f'{out_dir}test_sizes.pth')\n",
    "mask_pred_dir = out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 3\n",
    "ens_mask_pred = 0\n",
    "\n",
    "for m, seg_w in zip(models, seg_weights):\n",
    "    single_mask_pred = 0\n",
    "    for f in range(num_folds): # folds\n",
    "        if m == \"rx101-x448\" or m == \"rx101-fpn\" or m == \"b4-fpn\":\n",
    "            single_mask_pred += F.interpolate(\n",
    "                torch.load(f'{out_dir}{m}_test_{f}.pth'),\n",
    "                384, align_corners=False, mode='bilinear'\n",
    "                ) / num_folds\n",
    "        else:\n",
    "            single_mask_pred += torch.load(f'{out_dir}{m}_test_{f}.pth') / num_folds\n",
    "    ens_mask_pred += single_mask_pred * seg_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_mask_pred = torch.where(ens_mask_pred!=0, \n",
    "                            torch.sigmoid(ens_mask_pred), ens_mask_pred)\n",
    "ens_mask_pred = torch.stack([\n",
    "    ens_mask_pred[:, i, ...] > th\n",
    "    for i, th in enumerate(best_seg_thresholds)], 1)\n",
    "ens_mask_pred = ens_mask_pred.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ins_ratio = 0.000927\n",
    "min_art_ratio =  0.000293\n",
    "min_sat_ratio = 0.000380\n",
    "\n",
    "for out, i, o_sz in zip(ens_mask_pred, img_id, orig_size):\n",
    "    out = F.interpolate(out.unsqueeze(0), o_sz,\n",
    "        mode=\"bilinear\", align_corners=False)\n",
    "    out = out.squeeze(0)\n",
    "\n",
    "    area = np.prod(out.shape[1:])\n",
    "    instrument_area = out[0].sum()\n",
    "    artefact_area = out[2].sum()\n",
    "    saturation_area = out[-1].sum()\n",
    "    \n",
    "    if instrument_area > 0:\n",
    "        ins_ratio = instrument_area / area\n",
    "        if ins_ratio < min_ins_ratio: # less than min area in training set\n",
    "            print('Instrument ', i)\n",
    "            out[0] = 0\n",
    "    \n",
    "    if artefact_area > 0:\n",
    "        art_ratio = artefact_area / area\n",
    "        if art_ratio < min_art_ratio:\n",
    "            print('Artefact ', i)\n",
    "            out[2] = 0\n",
    "\n",
    "    if saturation_area > 0:\n",
    "        sat_ratio = saturation_area / area\n",
    "        if sat_ratio < min_sat_ratio:\n",
    "            print('Saturation ', i)\n",
    "            out[-1] = 0\n",
    "            \n",
    "    out = out.cpu().numpy().astype(np.uint8) * 255\n",
    "    save_path = os.path.join(mask_pred_dir, i+'.tif')\n",
    "    tiff.imwrite(save_path, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ins_ratio = 0.000927\n",
    "min_art_ratio =  0.000293\n",
    "min_sat_ratio = 0.000380\n",
    "\n",
    "for out, i, o_sz in zip(ens_mask_pred, img_id, orig_size):\n",
    "    out = F.interpolate(out.unsqueeze(0), o_sz,\n",
    "        mode=\"bilinear\", align_corners=False)\n",
    "    out = out.squeeze(0)\n",
    "\n",
    "    area = np.prod(out.shape[1:])\n",
    "    instrument_area = out[0].sum()\n",
    "    artefact_area = out[2].sum()\n",
    "    saturation_area = out[-1].sum()\n",
    "    \n",
    "    if instrument_area > 0:\n",
    "        ins_ratio = instrument_area / area\n",
    "        if ins_ratio < min_ins_ratio: # less than min area in training set\n",
    "            print('Instrument ', i)\n",
    "            out[0] = 0\n",
    "    \n",
    "    if artefact_area > 0:\n",
    "        art_ratio = artefact_area / area\n",
    "        if art_ratio < min_art_ratio:\n",
    "            print('Artefact ', i)\n",
    "            out[2] = 0\n",
    "\n",
    "    if saturation_area > 0:\n",
    "        sat_ratio = saturation_area / area\n",
    "        if sat_ratio < min_sat_ratio:\n",
    "            print('Saturation ', i)\n",
    "            out[-1] = 0\n",
    "            \n",
    "    out = out.cpu().numpy().astype(np.uint8) * 255\n",
    "    save_path = os.path.join(mask_pred_dir, i+'.tif')\n",
    "    tiff.imwrite(save_path, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Segmentation threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_seg_thresholds = []\n",
    "\n",
    "# for i in range(5): # 5 classes\n",
    "#     cls_out = ens_mask_output[:, i, ...].unsqueeze(1)\n",
    "#     cls_mask = valid_mask[:, i, ...].unsqueeze(1)\n",
    "#     _grid_dice_scores = []\n",
    "#     _grid_ious = []\n",
    "#     for thresh in _grid_thresholds:\n",
    "#         _grid_dice_scores.append(binary_dice_metric(cls_out, cls_mask, thresh).mean().item())\n",
    "#         _grid_ious.append(binary_iou_metric(cls_out, cls_mask, thresh).mean().item())\n",
    "#     best_t = _grid_thresholds[np.argmax(_grid_dice_scores)]\n",
    "# #     best_t = _grid_thresholds[np.argmax(_grid_ious)]\n",
    "#     best_dice = np.max(_grid_dice_scores)\n",
    "#     best_iou = np.max(_grid_ious)\n",
    "#     best_seg_thresholds.append(best_t)\n",
    "\n",
    "# # for i in range(5):\n",
    "# for i in range(1):\n",
    "#     valid_dice = binary_dice_metric(\n",
    "#         ens_mask_output, valid_mask, best_seg_thresholds)\n",
    "#     valid_iou = binary_iou_metric(\n",
    "#         ens_mask_output, valid_mask, best_seg_thresholds)\n",
    "    \n",
    "#     print(f'Dice Score - Fold {i}: ', valid_dice.mean(0).mean(0).item())\n",
    "#     print(f'IoU - Fold {i}: ', valid_iou.mean(0).mean(0).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('py37': conda)",
   "language": "python",
   "name": "python37564bitpy37condaf40bfcc33e5346358ccdaf0acfeb971b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
